{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])  # с ru хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.2):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "# Automatic brightness and contrast optimization with optional histogram clipping\n",
    "def automatic_brightness_and_contrast(image, clip_hist_percent=1):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate grayscale histogram\n",
    "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
    "    hist_size = len(hist)\n",
    "    \n",
    "    # Calculate cumulative distribution from the histogram\n",
    "    accumulator = []\n",
    "    accumulator.append(float(hist[0]))\n",
    "    for index in range(1, hist_size):\n",
    "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
    "    \n",
    "    # Locate points to clip\n",
    "    maximum = accumulator[-1]\n",
    "    clip_hist_percent *= (maximum/100.0)\n",
    "    clip_hist_percent /= 2.0\n",
    "    \n",
    "    # Locate left cut\n",
    "    minimum_gray = 0\n",
    "    while accumulator[minimum_gray] < clip_hist_percent:\n",
    "        minimum_gray += 1\n",
    "    \n",
    "    # Locate right cut\n",
    "    maximum_gray = hist_size -1\n",
    "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
    "        maximum_gray -= 1\n",
    "    \n",
    "    # Calculate alpha and beta values\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = -minimum_gray * alpha  \n",
    "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return (auto_result, alpha, beta)\n",
    "\n",
    "def clahe(frame):\n",
    "\n",
    "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
    "\n",
    "    # Converting image from LAB Color model to BGR color space\n",
    "    image_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    return image_clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preparation(frame):\n",
    "\n",
    "    # minmal size rectangle, px   \n",
    "    frame_for_auto = frame\n",
    "    frame_for_auto = cv2.fastNlMeansDenoisingColored(frame_for_auto ,None, 2, 2, 4, 4)\n",
    "    frame_for_auto = clahe(frame_for_auto)\n",
    "    frame_for_auto = adjust_gamma(frame_for_auto)        \n",
    "    \n",
    "    frame_auto, alpha, betta = automatic_brightness_and_contrast(frame_for_auto, clip_hist_percent=1)\n",
    "\n",
    "    out_frame = frame_auto\n",
    "    return out_frame\n",
    "\n",
    "def get_rects(frame):\n",
    "    minSize = int(frame.shape[0]/2.1)\n",
    "    return reader.readtext(frame, min_size = minSize, width_ths=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_processing(filename, out_filename='video'):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'X264')    \n",
    "    # out=cv2.VideoWriter(f'{out_filename}.mkv',\n",
    "    #                     fourcc,\n",
    "    #                     24, (frame_width, frame_height), True)\n",
    "\n",
    "    out=cv2.VideoWriter(f'{out_filename}.avi',\n",
    "                    cv2.VideoWriter_fourcc('D','I','V','X'),\n",
    "                    24, (frame_width, frame_height), True)\n",
    "\n",
    "    # ind = 0\n",
    "    # errInd = 49\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "    else:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_for_rect = frame\n",
    "            frame_for_rect = image_preparation(frame)\n",
    "            rects = get_rects(frame_for_rect) # OCR function\n",
    "\n",
    "            # frame = frame_for_rect\n",
    "           \n",
    "            if len(rects) > 0:\n",
    "                for elem in rects:\n",
    "                    number_str = re.sub(\"[^0-9]\", \"\", elem[1].replace(\" \", \"\"))                    \n",
    "                    if len(number_str) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # если символов меньше или больше 8, то нужно добавлять в датасет для обучения\n",
    "                    # дополнительно можно проверять верность полученного номера (по принципу его формирования)                    \n",
    "\n",
    "                    frame = cv2.rectangle(frame, np.array(elem[0][0]).astype(int), np.array(elem[0][2]).astype(int), (0, 0, 255), 2, )\n",
    "                    frame = cv2.putText(frame, number_str,\n",
    "                                        np.array(elem[0][0]).astype(int), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.2,\n",
    "                                        color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            # ind += 1\n",
    "\n",
    "            cv2.imshow('Vagons', frame)\n",
    "            out.write(frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27: # Esc нажать для остановки видео\n",
    "                break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run_processing('Sample/vagons.mp4', out_filename='processed_cisterns')\n",
    "run_processing('Sample/cisterns.avi', out_filename='processed_cisterns1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d30e6d4e6473c55ee31536bc57169ace291c153da81c0a4bb3e2b2828384d15a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
