{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])  # с ru хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.2):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "# Automatic brightness and contrast optimization with optional histogram clipping\n",
    "def automatic_brightness_and_contrast(image, clip_hist_percent=1):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate grayscale histogram\n",
    "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
    "    hist_size = len(hist)\n",
    "    \n",
    "    # Calculate cumulative distribution from the histogram\n",
    "    accumulator = []\n",
    "    accumulator.append(float(hist[0]))\n",
    "    for index in range(1, hist_size):\n",
    "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
    "    \n",
    "    # Locate points to clip\n",
    "    maximum = accumulator[-1]\n",
    "    clip_hist_percent *= (maximum/100.0)\n",
    "    clip_hist_percent /= 2.0\n",
    "    \n",
    "    # Locate left cut\n",
    "    minimum_gray = 0\n",
    "    while accumulator[minimum_gray] < clip_hist_percent:\n",
    "        minimum_gray += 1\n",
    "    \n",
    "    # Locate right cut\n",
    "    maximum_gray = hist_size -1\n",
    "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
    "        maximum_gray -= 1\n",
    "    \n",
    "    # Calculate alpha and beta values\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = -minimum_gray * alpha  \n",
    "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return (auto_result, alpha, beta)\n",
    "\n",
    "def clahe(frame):\n",
    "    lab_image = cv2.cvtColor(frame, cv2.COLOR_BGR2Lab)\n",
    "    lab_planes = list(cv2.split(lab_image))\n",
    "    clahe = cv2.createCLAHE(clipLimit=4)\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    cv2.merge(lab_planes, lab_image)\n",
    "    image_clahe = cv2.cvtColor(lab_image, cv2.COLOR_Lab2BGR)\n",
    "\n",
    "    return image_clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preparation(frame):\n",
    "\n",
    "    # minmal size rectangle, px   \n",
    "    frame_for_auto = frame\n",
    "    frame_for_auto = cv2.fastNlMeansDenoisingColored(frame_for_auto ,None, 1, 1, 2, 2)\n",
    "    frame_for_auto = clahe(frame_for_auto)\n",
    "    frame_for_auto = adjust_gamma(frame_for_auto)    \n",
    "    # frame_for_auto = cv2.fastNlMeansDenoisingColored(frame_for_auto ,None, 2, 2, 10, 10)\n",
    "    \n",
    "    frame_auto, alpha, betta = automatic_brightness_and_contrast(frame_for_auto, clip_hist_percent=1)\n",
    "    \n",
    "    frameG = cv2.blur(frame_auto, (50, 50))\n",
    "    frameW = cv2.addWeighted(frame_auto, -3, frameG, 2, 300)\n",
    "    # frameW = cv2.fastNlMeansDenoisingColored(frameW ,None, 5, 5, 22, 22)\n",
    "    frameW = cv2.fastNlMeansDenoisingColored(frameW ,None, 3, 3, 12, 12)\n",
    "\n",
    "    return frameW\n",
    "\n",
    "def get_rects(frame):\n",
    "    minSize = int(frame.shape[0]/3)\n",
    "    return reader.readtext(frame, canvas_size = 3000, min_size = minSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_processing(filename, size, out_filename='video'):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'X264')    \n",
    "    out=cv2.VideoWriter(f'{out_filename}.mkv',\n",
    "                        fourcc,\n",
    "                        24, size, True)\n",
    "\n",
    "    # ind = 0\n",
    "    # errInd = 49\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "    else:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_for_rect = frame\n",
    "            frame_for_rect = image_preparation(frame)\n",
    "            rects = get_rects(frame_for_rect) # OCR function\n",
    "           \n",
    "            if len(rects) > 0:\n",
    "                for elem in rects:\n",
    "                    number_str = re.sub(\"[^0-9]\", \"\", elem[1].replace(\" \", \"\"))                    \n",
    "                    if len(number_str) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # если символов меньше или больше 8, то нужно добавлять в датасет для обучения\n",
    "                    # дополнительно можно проверять верность полученного номера (по принципу его формирования)                    \n",
    "\n",
    "                    frame = cv2.rectangle(frame, np.array(elem[0][0]).astype(int), np.array(elem[0][2]).astype(int), (0, 0, 255), 2, )\n",
    "                    frame = cv2.putText(frame, number_str,\n",
    "                                        np.array(elem[0][0]).astype(int), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.2,\n",
    "                                        color=(0, 0, 255), thickness=2)\n",
    "\n",
    "            # ind += 1\n",
    "\n",
    "            cv2.imshow('Vagons', frame)\n",
    "            out.write(frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27: # Esc нажать для остановки видео\n",
    "                break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_processing('Sample/vagons.mp4', (640, 480), out_filename='processed_vagons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('wagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef7841281f311a33cbf7593ae1068283e11f36c84c6e09777bba501943e06382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
